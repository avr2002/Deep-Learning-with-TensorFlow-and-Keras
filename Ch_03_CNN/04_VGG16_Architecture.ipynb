{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639032ce-0f97-4c7e-9bfb-6770842635cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe1cbf-6ac0-413f-8e0a-1f9cf9320cf7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## VGG16 Architecture\n",
    "\n",
    "5 layers of `(Padding, Convolution, Padding, Convolution, MaxPool)`, then a fully connected Dense layer, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a82ef0b-22b5-4f03-bc5e-b5e2bfdc68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a VGG16 network\n",
    "\n",
    "def VGG_16(weights_path=None):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.ZeroPadding2D((1,1)))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    #top layer of the VGG net\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896e182-72db-456a-8109-b70091b8a544",
   "metadata": {},
   "source": [
    "### Predicting Cats with VGG16 Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2b50cb-a471-47a8-a6a7-9364614e4417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Amit Vikram Raj'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8272d3-614c-4874-ab09-11448be6b774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d (ZeroPadding  (None, 226, 226, 3)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " zero_padding2d_1 (ZeroPaddi  (None, 226, 226, 64)     0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " zero_padding2d_2 (ZeroPaddi  (None, 114, 114, 64)     0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " zero_padding2d_3 (ZeroPaddi  (None, 114, 114, 128)    0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_4 (ZeroPaddi  (None, 58, 58, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " zero_padding2d_5 (ZeroPaddi  (None, 58, 58, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " zero_padding2d_6 (ZeroPaddi  (None, 58, 58, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_7 (ZeroPaddi  (None, 30, 30, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " zero_padding2d_8 (ZeroPaddi  (None, 30, 30, 512)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " zero_padding2d_9 (ZeroPaddi  (None, 30, 30, 512)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_10 (ZeroPadd  (None, 16, 16, 512)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " zero_padding2d_11 (ZeroPadd  (None, 16, 16, 512)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " zero_padding2d_12 (ZeroPadd  (None, 16, 16, 512)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "285\n"
     ]
    }
   ],
   "source": [
    "im = cv2.resize(cv2.imread('prediction_images/cat.jpg'), (224, 224)).astype(np.float32)\n",
    "#im = im.transpose((2,0,1))\n",
    "im = np.expand_dims(im, axis=0)\n",
    "\n",
    "# Test pretrained model\n",
    "path_file = \"./saved_model/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "model = VGG_16(path_file)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "out = model.predict(im)\n",
    "print(np.argmax(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705e781-1a97-420e-8a51-556386178677",
   "metadata": {},
   "source": [
    "`285` is returned with corresponds to \"Egyptian cat\".\n",
    "\n",
    "Impressive, isn't it? Our VGG16 network can successfully recognize\r\n",
    "images of catst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e08744-d686-48fc-bca0-49811fe1ae82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Using tf.keras built-in VGG16 net module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647189b9-0de1-49cf-b315-a82635a07024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0429c8-3dc3-41ae-b921-956a6612f4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "# pre built model with pre-trained weights on imagenet\n",
    "model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "853e689f-e2b7-4447-8c43-05da5a31c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "820\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhEElEQVR4nO3df3BU1eH38U9+kE0oJEFjNhAWA2pFCwZMJAb0Kz5uTZHB0l9DkUKaKg4WLZCqEJFQayHUFkpb0VQq2pmKoI5SKzQOXUTLYyQSiIoKaFHDg+4CpWRD0ASy5/nDr6srCWZDksNN3q+ZnZG75+6ePWLy9t69uzHGGCMAAABLYm1PAAAA9GzECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKyKtz2BtgiFQvrwww/Vt29fxcTE2J4OAABoA2OM6uvrNWDAAMXGtn78wxEx8uGHH8rj8dieBgAAaId9+/Zp4MCBrd7viBjp27evpE9fTHJysuXZAACAtggGg/J4POHf461xRIx8dmomOTmZGAEAwGG+6i0WvIEVAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYFXWMvPTSS5owYYIGDBigmJgYrVu37iv32bx5sy699FK5XC6df/75evTRR9sxVQAA0B1FHSMNDQ3Kzs7WihUr2jT+vffe0/jx43X11VerpqZGs2fP1k033aTnn38+6skCAIDuJ+rvphk3bpzGjRvX5vHl5eUaPHiwli5dKkm66KKLtGXLFv3ud79TQUFBtE8PAAC6mU5/z0hlZaW8Xm/EtoKCAlVWVra6T2Njo4LBYMQNAIAvq/3PMf3pxX/raOMJ21PBaej0GPH7/XK73RHb3G63gsGgPv744xb3KSsrU0pKSvjm8Xg6e5oAAAcqWP6Syv6xS4vWv2V7KjgNZ+TVNCUlJaqrqwvf9u3bZ3tKAIAz0MfHmyVJW/cetjwTnI6o3zMSrYyMDAUCgYhtgUBAycnJSkpKanEfl8sll8vV2VMDAABngE4/MpKfny+fzxexbePGjcrPz+/spwYAAA4QdYwcPXpUNTU1qqmpkfTppbs1NTWqra2V9OkplmnTpoXHz5gxQ3v37tWdd96pXbt26YEHHtATTzyhOXPmdMwrAAAAjhZ1jGzbtk0jR47UyJEjJUnFxcUaOXKkSktLJUkfffRROEwkafDgwVq/fr02btyo7OxsLV26VH/+85+5rBcAAEhqx3tGxo4dK2NMq/e39OmqY8eO1Y4dO6J9KgAA0AOckVfTAACAnoMYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXtipEVK1YoKytLiYmJysvLU1VV1SnHL1++XBdeeKGSkpLk8Xg0Z84cffLJJ+2aMAAA6F6ijpG1a9equLhYCxcu1Pbt25Wdna2CggIdOHCgxfGrV6/WvHnztHDhQr399tt6+OGHtXbtWt11112nPXkAAOB8UcfIsmXLNH36dBUVFeniiy9WeXm5evfurVWrVrU4/uWXX9aYMWN0ww03KCsrS9dee60mT578lUdTAABAzxBVjDQ1Nam6ulper/fzB4iNldfrVWVlZYv7jB49WtXV1eH42Lt3rzZs2KDrrrvuNKYNAAC6i/hoBh86dEjNzc1yu90R291ut3bt2tXiPjfccIMOHTqkK664QsYYnThxQjNmzDjlaZrGxkY1NjaG/xwMBqOZJgAAcJBOv5pm8+bNWrx4sR544AFt375dTz/9tNavX69777231X3KysqUkpISvnk8ns6eJgAAsCSqIyNpaWmKi4tTIBCI2B4IBJSRkdHiPgsWLNDUqVN10003SZKGDx+uhoYG3XzzzZo/f75iY0/uoZKSEhUXF4f/HAwGCRIAALqpqI6MJCQkKCcnRz6fL7wtFArJ5/MpPz+/xX2OHTt2UnDExcVJkowxLe7jcrmUnJwccQMAAN1TVEdGJKm4uFiFhYXKzc3VqFGjtHz5cjU0NKioqEiSNG3aNGVmZqqsrEySNGHCBC1btkwjR45UXl6e3n33XS1YsEATJkwIRwkAAOi5oo6RSZMm6eDBgyotLZXf79eIESNUUVERflNrbW1txJGQu+++WzExMbr77ru1f/9+nXPOOZowYYIWLVrUca8CAAA4Voxp7VzJGSQYDColJUV1dXWcsgEAhGXNWy9JGpL2NW26fazdyeAkbf39zXfTAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq9oVIytWrFBWVpYSExOVl5enqqqqU44/cuSIZs6cqf79+8vlcunrX/+6NmzY0K4JAwCA7iU+2h3Wrl2r4uJilZeXKy8vT8uXL1dBQYF2796t9PT0k8Y3NTXpm9/8ptLT0/XUU08pMzNTH3zwgVJTUzti/gAAwOGijpFly5Zp+vTpKioqkiSVl5dr/fr1WrVqlebNm3fS+FWrVunw4cN6+eWX1atXL0lSVlbW6c0aAAB0G1GdpmlqalJ1dbW8Xu/nDxAbK6/Xq8rKyhb3efbZZ5Wfn6+ZM2fK7XZr2LBhWrx4sZqbm1t9nsbGRgWDwYgbAADonqKKkUOHDqm5uVlutztiu9vtlt/vb3GfvXv36qmnnlJzc7M2bNigBQsWaOnSpfrVr37V6vOUlZUpJSUlfPN4PNFMEwAAOEinX00TCoWUnp6uhx56SDk5OZo0aZLmz5+v8vLyVvcpKSlRXV1d+LZv377OniYAALAkqveMpKWlKS4uToFAIGJ7IBBQRkZGi/v0799fvXr1UlxcXHjbRRddJL/fr6amJiUkJJy0j8vlksvlimZqAADAoaI6MpKQkKCcnBz5fL7wtlAoJJ/Pp/z8/Bb3GTNmjN59912FQqHwtj179qh///4thggAAOhZoj5NU1xcrJUrV+ovf/mL3n77bd1yyy1qaGgIX10zbdo0lZSUhMffcsstOnz4sGbNmqU9e/Zo/fr1Wrx4sWbOnNlxrwIAADhW1Jf2Tpo0SQcPHlRpaan8fr9GjBihioqK8Jtaa2trFRv7eeN4PB49//zzmjNnji655BJlZmZq1qxZmjt3bse9CgAA4FgxxhhjexJfJRgMKiUlRXV1dUpOTrY9HQDAGSJr3npJ0pC0r2nT7WPtTgYnaevvb76bBgAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwKp2xciKFSuUlZWlxMRE5eXlqaqqqk37rVmzRjExMZo4cWJ7nhYAAHRDUcfI2rVrVVxcrIULF2r79u3Kzs5WQUGBDhw4cMr93n//fd1+++268sor2z1ZAADQ/UQdI8uWLdP06dNVVFSkiy++WOXl5erdu7dWrVrV6j7Nzc2aMmWK7rnnHg0ZMuS0JgwAALqXqGKkqalJ1dXV8nq9nz9AbKy8Xq8qKytb3e+Xv/yl0tPTdeONN7bpeRobGxUMBiNuAACge4oqRg4dOqTm5ma53e6I7W63W36/v8V9tmzZoocfflgrV65s8/OUlZUpJSUlfPN4PNFMEwAAOEinXk1TX1+vqVOnauXKlUpLS2vzfiUlJaqrqwvf9u3b14mzBAAANsVHMzgtLU1xcXEKBAIR2wOBgDIyMk4a/+9//1vvv/++JkyYEN4WCoU+feL4eO3evVvnnXfeSfu5XC65XK5opgYAABwqqiMjCQkJysnJkc/nC28LhULy+XzKz88/afzQoUP1xhtvqKamJny7/vrrdfXVV6umpobTLwAAILojI5JUXFyswsJC5ebmatSoUVq+fLkaGhpUVFQkSZo2bZoyMzNVVlamxMREDRs2LGL/1NRUSTppOwAA6JmijpFJkybp4MGDKi0tld/v14gRI1RRURF+U2ttba1iY/lgVwAA0DYxxhhjexJfJRgMKiUlRXV1dUpOTrY9HQDAGSJr3npJ0pC0r2nT7WPtTgYnaevvbw5hAAAAq4gRAABgFTECAACsIkYAAM4XY3sCOB3ECADA+c74SzFwKsQIAACwihgBADgfp2kcjRgBADgfp2kcjRgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgBwvhjbE8DpIEYAAM5nbE8Ap4MYAQAAVhEjAADn4zSNoxEjAADn4zSNoxEjAADAKmIEAOB8nKZxNGIEAOB8nKZxNGIEAABYRYwAAJyP0zSORowAAJyP0zSORowAAACriBEAAGAVMQIAAKwiRgAAgFXECADAkYzhXavdBTECAACsIkYAAIBVxAgAwJE4S9N9ECMAAMAqYgQAAFhFjAAAHImzNN0HMQIAAKwiRgAAgFXECADAkfjQs+6DGAEAAFYRIwAAwKp2xciKFSuUlZWlxMRE5eXlqaqqqtWxK1eu1JVXXql+/fqpX79+8nq9pxwPAEBbcJKm+4g6RtauXavi4mItXLhQ27dvV3Z2tgoKCnTgwIEWx2/evFmTJ0/WCy+8oMrKSnk8Hl177bXav3//aU8eAAA4X4yJ8h1AeXl5uuyyy3T//fdLkkKhkDwej2677TbNmzfvK/dvbm5Wv379dP/992vatGltes5gMKiUlBTV1dUpOTk5mukCALqp480hXTD/H5KkIed8TZt+PtbuhHCStv7+jurISFNTk6qrq+X1ej9/gNhYeb1eVVZWtukxjh07puPHj+uss85qdUxjY6OCwWDEDQCAL4r4X2nO2ThaVDFy6NAhNTc3y+12R2x3u93y+/1teoy5c+dqwIABEUHzZWVlZUpJSQnfPB5PNNMEAAAO0qVX0yxZskRr1qzRM888o8TExFbHlZSUqK6uLnzbt29fF84SAOA4MbYngNMRH83gtLQ0xcXFKRAIRGwPBALKyMg45b6//e1vtWTJEv3zn//UJZdccsqxLpdLLpcrmqkBAHoY88VzM5ymcbSojowkJCQoJydHPp8vvC0UCsnn8yk/P7/V/e677z7de++9qqioUG5ubvtnCwAAup2ojoxIUnFxsQoLC5Wbm6tRo0Zp+fLlamhoUFFRkSRp2rRpyszMVFlZmSTp17/+tUpLS7V69WplZWWF31vSp08f9enTpwNfCgCgx+I0jaNFHSOTJk3SwYMHVVpaKr/frxEjRqiioiL8ptba2lrFxn5+wOXBBx9UU1OTvv/970c8zsKFC/WLX/zi9GYPAOixuJqm+4j6c0Zs4HNGAABf9snxZg1dUCFJGpL2NW26fazdCeEknfI5IwAAnJE4TeNoxAgAwPnO+GP8OBViBAAAWEWMAACcj9M0jkaMAAAciatpug9iBAAAWEWMAACcj9M0jkaMAAAcie+m6T6IEQAAYBUxAgBwpDP/88PRVsQIAACwihgBAABWESMAAEfiLE33QYwAAACriBEAAGAVMQIAcCTD5TTdBjECAACsIkYAAIBVxAgAwJE4SdN9ECMAAMAqYgQA4Hx8a6+jESMAAEeKuJiGczaORowAAACriBEAgPNxmsbRiBEAgDNxmqbbIEYAAIBVxAgAwPk4TeNoxAgAwJHMF8/NcJrG0YgRAABgFTECAHA+TtM4GjECAHAkPvSs+yBGAACAVcQIAMD5OE3jaMQIAMCRTKt/gNMQIwAAwCpiBADgfJymcTRiBADgSMbwoWfdBTECAACsIkYAAM7HaRpHI0YAAI7E1TTdBzECAACsIkYAAI7E+1e7D2IEAABYRYwAAACriBEAgCOZL5ycifjMETgOMQIAAKwiRgAAgFXECADAmbiaptsgRgAAgFXECAAAsIoYAQA40hdPzXAxjbMRIwAAwCpiBAAAWEWMAAAcKfK7aThP42TECAAAsIoYAQAAVrUrRlasWKGsrCwlJiYqLy9PVVVVpxz/5JNPaujQoUpMTNTw4cO1YcOGdk0WAIDPRH43jcWJ4LRFHSNr165VcXGxFi5cqO3btys7O1sFBQU6cOBAi+NffvllTZ48WTfeeKN27NihiRMnauLEidq5c+dpTx4AADhfjInyqw7z8vJ02WWX6f7775ckhUIheTwe3XbbbZo3b95J4ydNmqSGhgY999xz4W2XX365RowYofLy8jY9ZzAYVEpKiurq6pScnBzNdAEA3dRHdR8rv2yTJGlgvyRtmft/LM8IX9bW39/x0TxoU1OTqqurVVJSEt4WGxsrr9erysrKFveprKxUcXFxxLaCggKtW7eu1edpbGxUY2Nj+M/BYDCaabbZw1ve0//777FOeWwAQOdqaDwR/ucjx47rnr+/aXE2zveTMYPlOau3leeOKkYOHTqk5uZmud3uiO1ut1u7du1qcR+/39/ieL/f3+rzlJWV6Z577olmau2y/vUPtb32SKc/DwCgcx1tPKFH/u/7tqfhaBOyBzgjRrpKSUlJxNGUYDAoj8fT4c/zvZyByj/v7A5/XABA1zlY36hz+rpsT8Px3MmJ1p47qhhJS0tTXFycAoFAxPZAIKCMjIwW98nIyIhqvCS5XC65XJ3/F2tK3rmd/hwAAODUorqaJiEhQTk5OfL5fOFtoVBIPp9P+fn5Le6Tn58fMV6SNm7c2Op4AADQs0R9mqa4uFiFhYXKzc3VqFGjtHz5cjU0NKioqEiSNG3aNGVmZqqsrEySNGvWLF111VVaunSpxo8frzVr1mjbtm166KGHOvaVAAAAR4o6RiZNmqSDBw+qtLRUfr9fI0aMUEVFRfhNqrW1tYqN/fyAy+jRo7V69Wrdfffduuuuu3TBBRdo3bp1GjZsWMe9CgAA4FhRf86IDXzOCAAAztPW3998Nw0AALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALAq6o+Dt+GzD4kNBoOWZwIAANrqs9/bX/Vh746Ikfr6ekmSx+OxPBMAABCt+vp6paSktHq/I76bJhQK6cMPP1Tfvn0VExPTYY8bDAbl8Xi0b98+vvOmk7HWXYN17hqsc9dgnbtOZ621MUb19fUaMGBAxJfofpkjjozExsZq4MCBnfb4ycnJ/EXvIqx112Cduwbr3DVY567TGWt9qiMin+ENrAAAwCpiBAAAWNWjY8TlcmnhwoVyuVy2p9LtsdZdg3XuGqxz12Cdu47ttXbEG1gBAED31aOPjAAAAPuIEQAAYBUxAgAArCJGAACAVT06RlasWKGsrCwlJiYqLy9PVVVVtqfkGGVlZbrsssvUt29fpaena+LEidq9e3fEmE8++UQzZ87U2WefrT59+uh73/ueAoFAxJja2lqNHz9evXv3Vnp6uu644w6dOHGiK1+KoyxZskQxMTGaPXt2eBvr3HH279+vH/3oRzr77LOVlJSk4cOHa9u2beH7jTEqLS1V//79lZSUJK/Xq3feeSfiMQ4fPqwpU6YoOTlZqampuvHGG3X06NGufilnrObmZi1YsECDBw9WUlKSzjvvPN17770R313COrfPSy+9pAkTJmjAgAGKiYnRunXrIu7vqHV9/fXXdeWVVyoxMVEej0f33Xff6U/e9FBr1qwxCQkJZtWqVebNN98006dPN6mpqSYQCNiemiMUFBSYRx55xOzcudPU1NSY6667zgwaNMgcPXo0PGbGjBnG4/EYn89ntm3bZi6//HIzevTo8P0nTpwww4YNM16v1+zYscNs2LDBpKWlmZKSEhsv6YxXVVVlsrKyzCWXXGJmzZoV3s46d4zDhw+bc8891/z4xz82W7duNXv37jXPP/+8effdd8NjlixZYlJSUsy6devMa6+9Zq6//nozePBg8/HHH4fHfOtb3zLZ2dnmlVdeMf/617/M+eefbyZPnmzjJZ2RFi1aZM4++2zz3HPPmffee888+eSTpk+fPub3v/99eAzr3D4bNmww8+fPN08//bSRZJ555pmI+ztiXevq6ozb7TZTpkwxO3fuNI8//rhJSkoyf/rTn05r7j02RkaNGmVmzpwZ/nNzc7MZMGCAKSsrszgr5zpw4ICRZF588UVjjDFHjhwxvXr1Mk8++WR4zNtvv20kmcrKSmPMp//hxMbGGr/fHx7z4IMPmuTkZNPY2Ni1L+AMV19fby644AKzceNGc9VVV4VjhHXuOHPnzjVXXHFFq/eHQiGTkZFhfvOb34S3HTlyxLhcLvP4448bY4x56623jCTz6quvhsf84x//MDExMWb//v2dN3kHGT9+vPnJT34Sse273/2umTJlijGGde4oX46RjlrXBx54wPTr1y/iZ8fcuXPNhRdeeFrz7ZGnaZqamlRdXS2v1xveFhsbK6/Xq8rKSoszc666ujpJ0llnnSVJqq6u1vHjxyPWeOjQoRo0aFB4jSsrKzV8+HC53e7wmIKCAgWDQb355ptdOPsz38yZMzV+/PiI9ZRY54707LPPKjc3Vz/4wQ+Unp6ukSNHauXKleH733vvPfn9/oi1TklJUV5eXsRap6amKjc3NzzG6/UqNjZWW7du7boXcwYbPXq0fD6f9uzZI0l67bXXtGXLFo0bN04S69xZOmpdKysr9T//8z9KSEgIjykoKNDu3bv13//+t93zc8QX5XW0Q4cOqbm5OeKHsyS53W7t2rXL0qycKxQKafbs2RozZoyGDRsmSfL7/UpISFBqamrEWLfbLb/fHx7T0r+Dz+7Dp9asWaPt27fr1VdfPek+1rnj7N27Vw8++KCKi4t111136dVXX9XPfvYzJSQkqLCwMLxWLa3lF9c6PT094v74+HidddZZrPX/mjdvnoLBoIYOHaq4uDg1Nzdr0aJFmjJliiSxzp2ko9bV7/dr8ODBJz3GZ/f169evXfPrkTGCjjVz5kzt3LlTW7ZssT2Vbmffvn2aNWuWNm7cqMTERNvT6dZCoZByc3O1ePFiSdLIkSO1c+dOlZeXq7Cw0PLsuo8nnnhCjz32mFavXq1vfOMbqqmp0ezZszVgwADWuQfrkadp0tLSFBcXd9IVB4FAQBkZGZZm5Uy33nqrnnvuOb3wwgsaOHBgeHtGRoaampp05MiRiPFfXOOMjIwW/x18dh8+PQ1z4MABXXrppYqPj1d8fLxefPFF/eEPf1B8fLzcbjfr3EH69++viy++OGLbRRddpNraWkmfr9Wpfm5kZGTowIEDEfefOHFChw8fZq3/1x133KF58+bphz/8oYYPH66pU6dqzpw5Kisrk8Q6d5aOWtfO+nnSI2MkISFBOTk58vl84W2hUEg+n0/5+fkWZ+YcxhjdeuuteuaZZ7Rp06aTDtvl5OSoV69eEWu8e/du1dbWhtc4Pz9fb7zxRsRf/o0bNyo5OfmkXwo91TXXXKM33nhDNTU14Vtubq6mTJkS/mfWuWOMGTPmpMvT9+zZo3PPPVeSNHjwYGVkZESsdTAY1NatWyPW+siRI6qurg6P2bRpk0KhkPLy8rrgVZz5jh07ptjYyF89cXFxCoVCkljnztJR65qfn6+XXnpJx48fD4/ZuHGjLrzwwnafopHUsy/tdblc5tFHHzVvvfWWufnmm01qamrEFQdo3S233GJSUlLM5s2bzUcffRS+HTt2LDxmxowZZtCgQWbTpk1m27ZtJj8/3+Tn54fv/+yS02uvvdbU1NSYiooKc84553DJ6Vf44tU0xrDOHaWqqsrEx8ebRYsWmXfeecc89thjpnfv3uavf/1reMySJUtMamqq+dvf/mZef/118+1vf7vFSyNHjhxptm7darZs2WIuuOCCHn/J6RcVFhaazMzM8KW9Tz/9tElLSzN33nlneAzr3D719fVmx44dZseOHUaSWbZsmdmxY4f54IMPjDEds65HjhwxbrfbTJ061ezcudOsWbPG9O7dm0t7T8cf//hHM2jQIJOQkGBGjRplXnnlFdtTcgxJLd4eeeSR8JiPP/7Y/PSnPzX9+vUzvXv3Nt/5znfMRx99FPE477//vhk3bpxJSkoyaWlp5uc//7k5fvx4F78aZ/lyjLDOHefvf/+7GTZsmHG5XGbo0KHmoYceirg/FAqZBQsWGLfbbVwul7nmmmvM7t27I8b85z//MZMnTzZ9+vQxycnJpqioyNTX13flyzijBYNBM2vWLDNo0CCTmJhohgwZYubPnx9xqSjr3D4vvPBCiz+XCwsLjTEdt66vvfaaueKKK4zL5TKZmZlmyZIlpz33GGO+8LF3AAAAXaxHvmcEAACcOYgRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBV/x8hLvA5fxseoAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resize into VGG16 trained images' format\n",
    "im = cv2.resize(cv2.imread('prediction_images/steam-locomotive.jpg'), (224, 224))\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im.astype(np.float32)\n",
    "\n",
    "# predict\n",
    "out = model.predict(im)\n",
    "index = np.argmax(out)\n",
    "print(index)\n",
    "\n",
    "plt.plot(out.ravel())\n",
    "plt.show();\n",
    "\n",
    "# o/p --> 820 is for steaming train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607eb1eb-6d93-4675-8c6f-bc2c55ecca24",
   "metadata": {},
   "source": [
    "## Recycling pre-built deep learning models for extracting features\n",
    "\n",
    "One very simple idea is to use VGG 16, and more generally DCNN, for \n",
    "feature extraction. This code implements the idea by extracting feature \r\n",
    "from a specific layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38f1eb9-3496-4645-8b02-28693c9b76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
    "\n",
    "from tensorflow.keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9458d7-185c-4678-9bc1-4c7fa3a6bffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.functional.Functional object at 0x000002283945E230> \n",
      "\n",
      "0 input_1 [(None, 224, 224, 3)]\n",
      "1 block1_conv1 (None, 224, 224, 64)\n",
      "2 block1_conv2 (None, 224, 224, 64)\n",
      "3 block1_pool (None, 112, 112, 64)\n",
      "4 block2_conv1 (None, 112, 112, 128)\n",
      "5 block2_conv2 (None, 112, 112, 128)\n",
      "6 block2_pool (None, 56, 56, 128)\n",
      "7 block3_conv1 (None, 56, 56, 256)\n",
      "8 block3_conv2 (None, 56, 56, 256)\n",
      "9 block3_conv3 (None, 56, 56, 256)\n",
      "10 block3_pool (None, 28, 28, 256)\n",
      "11 block4_conv1 (None, 28, 28, 512)\n",
      "12 block4_conv2 (None, 28, 28, 512)\n",
      "13 block4_conv3 (None, 28, 28, 512)\n",
      "14 block4_pool (None, 14, 14, 512)\n",
      "15 block5_conv1 (None, 14, 14, 512)\n",
      "16 block5_conv2 (None, 14, 14, 512)\n",
      "17 block5_conv3 (None, 14, 14, 512)\n",
      "18 block5_pool (None, 7, 7, 512)\n",
      "19 flatten (None, 25088)\n",
      "20 fc1 (None, 4096)\n",
      "21 fc2 (None, 4096)\n",
      "22 predictions (None, 1000)\n"
     ]
    }
   ],
   "source": [
    "# pre-build model with pre-trained weights on imagenet\n",
    "base_model = VGG16(weights='imagenet', include_top=True)\n",
    "print(base_model, \"\\n\")\n",
    "\n",
    "# All layers of VGG16\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e74a5c-bfb1-48ef-9bc8-2033c23b5d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "array([[[[  0.      ,   0.      ,  39.057278, ...,   0.      ,\n",
      "            0.      ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "          261.47574 ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "          376.41232 ,   0.      ],\n",
      "         ...,\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "          175.45848 ,   0.      ],\n",
      "         [  0.      ,   0.      ,  32.01233 , ...,   0.      ,\n",
      "            0.      ,   0.      ],\n",
      "         [  0.      ,   0.      ,  76.265816, ...,   0.      ,\n",
      "            0.      ,   0.      ]],\n",
      "\n",
      "        [[  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "           50.82755 ,   0.      ],\n",
      "         [  0.      ,   0.      ,  44.37474 , ...,   0.      ,\n",
      "          123.88842 ,   0.      ],\n",
      "         [  0.      ,   0.      ,  27.84265 , ...,   0.      ,\n",
      "          573.3558  ,   0.      ],\n",
      "         ...,\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "          683.3251  ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "           18.327875,   0.      ],\n",
      "         [  0.      ,   0.      ,  60.602158, ...,   0.      ,\n",
      "            0.      ,   0.      ]],\n",
      "\n",
      "        [[  0.      ,   0.      ,  27.607662, ...,   0.      ,\n",
      "            0.      ,   0.      ],\n",
      "         [  0.      , 372.522   ,   0.      , ...,  29.04391 ,\n",
      "            0.      ,   0.      ],\n",
      "         [  0.      ,  34.896393, 105.478035, ...,   0.      ,\n",
      "            0.      ,   0.      ],\n",
      "         ...,\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "          823.4585  ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "           95.24839 ,   0.      ],\n",
      "         [  0.      ,   0.      ,  20.043648, ...,   0.      ,\n",
      "            0.      ,   0.      ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "           58.52735 ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "            0.      ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "            0.      ,   0.      ],\n",
      "         ...,\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "          376.76556 ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "            0.      ,   0.      ],\n",
      "         [  0.      ,   0.      ,   9.006432, ...,   0.      ,\n",
      "            0.      ,   0.      ]],\n",
      "\n",
      "        [[  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "          112.5272  ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "           48.296066,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "            0.      ,   0.      ],\n",
      "         ...,\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "          340.14618 ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "            0.      ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "            0.      ,   0.      ]],\n",
      "\n",
      "        [[  0.      ,   0.      ,  33.47151 , ...,   0.      ,\n",
      "           89.49547 ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "          169.88101 ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "            0.      ,   0.      ],\n",
      "         ...,\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "          142.88644 ,   0.      ],\n",
      "         [  0.      ,   0.      ,   0.      , ...,   0.      ,\n",
      "           14.984388,   0.      ],\n",
      "         [  0.      ,   0.      ,  51.72733 , ...,   0.      ,\n",
      "            0.      ,   0.      ]]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Extract features from block4_pool block\n",
    "model = models.Model(inputs = base_model.input, \n",
    "                     outputs = base_model.get_layer('block4_pool').output)\n",
    "\n",
    "img_path = \"prediction_images/cat.jpg\"\n",
    "img = image.load_img(img_path, target_size=(224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# get the features from this block\n",
    "features = model.predict(x)\n",
    "pprint(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319cb81e-60c1-4973-bf79-40f534041faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14, 14, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed03bc8c-b201-4d81-9638-41addb264c44",
   "metadata": {},
   "source": [
    "You might wonder **why we want to extract the features from an intermediate layer in a DCNN?**\n",
    "\n",
    "- The reasoning is that as the network learns to classify images into categories, each layer learns to identify the features that are necessary to perform the final classification.\n",
    "\n",
    "    - **Lower layers identify lower-order features such as color and edges,** and \n",
    "        \n",
    "    - **higher layers compose these lower-order features into higher-order features such as shapes or objects.** \n",
    "        \n",
    "    - **Hence, the intermediate layer has the capability to extract important features from an image, and these features are more likely to help in different kinds of classification.** \n",
    "\n",
    "* **\n",
    "\n",
    "This has multiple advantages: \n",
    "\n",
    "- First, we can rely on publicly available large-scale training and transfer this learning to novel domains. \n",
    "\n",
    "- Second, we can save time on expensive training. \n",
    "\n",
    "- Third, we can provide reasonable solutions even when we don't have a large number of training examples for our domain.\n",
    "\n",
    "- We also get a good starting network shape for the task at hand, instead of guessing it. \n",
    "\n",
    "With this, we will conclude the overview of VGG16 CNNs, the last deep learning model defined in this chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
